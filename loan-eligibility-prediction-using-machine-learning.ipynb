{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan Eligibility Prediction Using Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement:\n",
    "\n",
    "The process of determining loan eligibility is critical for financial institutions to minimize risk while extending loans to individuals. This dataset consists of key demographic and financial information about loan applicants, including factors such as gender, marital status, income, credit history, loan amount, and property location. **The current challenge is to predict whether a loan applicant will be eligible for a loan in the future based on their profile.**\n",
    "\n",
    "# Objective:\n",
    "\n",
    "The goal of this analysis is to build a predictive model that can assess the eligibility of loan seekers by analyzing historical data. By doing so, the model will help financial institutions make informed decisions, improving approval accuracy and reducing the risk of loan defaults.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Useful Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.846582Z",
     "iopub.status.busy": "2024-11-18T17:19:00.846005Z",
     "iopub.status.idle": "2024-11-18T17:19:00.853551Z",
     "shell.execute_reply": "2024-11-18T17:19:00.852123Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.846521Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For handling warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.856859Z",
     "iopub.status.busy": "2024-11-18T17:19:00.856298Z",
     "iopub.status.idle": "2024-11-18T17:19:00.872381Z",
     "shell.execute_reply": "2024-11-18T17:19:00.871080Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.856804Z"
    }
   },
   "outputs": [],
   "source": [
    "train_file_path = '/kaggle/input/finance-loan-approval-prediction-data/train.csv'\n",
    "test_file_path = '/kaggle/input/finance-loan-approval-prediction-data/test.csv'\n",
    "\n",
    "df_train = pd.read_csv(train_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.904697Z",
     "iopub.status.busy": "2024-11-18T17:19:00.903434Z",
     "iopub.status.idle": "2024-11-18T17:19:00.950371Z",
     "shell.execute_reply": "2024-11-18T17:19:00.949049Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.904645Z"
    }
   },
   "outputs": [],
   "source": [
    "info = df_train.info() #brief information about the dataset\n",
    "description = df_train.describe() #Brief decription of columns\n",
    "quick_peek = df_train.head() #Taking a peek at the data\n",
    "data_shape = df_train.shape #knowing the datashape\n",
    "\n",
    "no_of_rows, no_of_columns = (data_shape) \n",
    "no_of_features = no_of_columns - 1\n",
    "tot_num_data = no_of_rows * no_of_columns\n",
    "\n",
    "print ('                                                     ')\n",
    "print (f'Brief info of the data:\\n{info}')\n",
    "print ('-----------------------------------------------------------------------')\n",
    "print ('                                                     ')\n",
    "print (f'Descriptions of Columns:\\n{description}')\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('                                                     ')\n",
    "print(f'A quick view of the dataset:\\n{quick_peek}')\n",
    "print ('------------------------------------------------------------------------')\n",
    "print ('                                                     ')\n",
    "print (f'shape of data:\\n{data_shape}')\n",
    "\n",
    "print (f'Number of rows: {no_of_rows}')\n",
    "print (f'Number of columns: {no_of_columns}')\n",
    "print (f'Number of features: {no_of_features}')\n",
    "print (f'Total number of data: {tot_num_data}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.953340Z",
     "iopub.status.busy": "2024-11-18T17:19:00.952947Z",
     "iopub.status.idle": "2024-11-18T17:19:00.963103Z",
     "shell.execute_reply": "2024-11-18T17:19:00.961599Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.953300Z"
    }
   },
   "outputs": [],
   "source": [
    "#Checking for missing values\n",
    "\n",
    "missing_values = df_train.isnull().sum()\n",
    "\n",
    "print ('Missing values in each column: \\n', missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.965632Z",
     "iopub.status.busy": "2024-11-18T17:19:00.965129Z",
     "iopub.status.idle": "2024-11-18T17:19:00.978468Z",
     "shell.execute_reply": "2024-11-18T17:19:00.976926Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.965579Z"
    }
   },
   "outputs": [],
   "source": [
    "# Percentage of missing values\n",
    "\n",
    "missing_percentage = (missing_values/len(df_train))*100\n",
    "\n",
    "print ('percentage of missing values: \\n', missing_percentage.astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling the missing values\n",
    "\n",
    "For categorical data columns (Gender, Married, Dependents, Self-employed, Credit history) the missing values will be filled with the **mode** of the column.\n",
    "\n",
    "However, numerical data columns (Loan amount. Loan amount term) will be filled with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:00.980345Z",
     "iopub.status.busy": "2024-11-18T17:19:00.979983Z",
     "iopub.status.idle": "2024-11-18T17:19:00.999846Z",
     "shell.execute_reply": "2024-11-18T17:19:00.998451Z",
     "shell.execute_reply.started": "2024-11-18T17:19:00.980308Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling categorical data\n",
    "\n",
    "df_train['Gender'] = df_train['Gender'].fillna(df_train['Gender'].mode()[0])\n",
    "df_train['Married'] = df_train['Married'].fillna(df_train['Married'].mode()[0])\n",
    "df_train['Dependents'] = df_train['Dependents'].fillna(df_train['Dependents'].mode()[0])\n",
    "df_train['Self_Employed'] = df_train['Self_Employed'].fillna(df_train['Self_Employed'].mode()[0])\n",
    "df_train['Credit_History'] = df_train['Credit_History'].fillna(df_train['Credit_History'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:01.003331Z",
     "iopub.status.busy": "2024-11-18T17:19:01.002878Z",
     "iopub.status.idle": "2024-11-18T17:19:01.018241Z",
     "shell.execute_reply": "2024-11-18T17:19:01.016426Z",
     "shell.execute_reply.started": "2024-11-18T17:19:01.003286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Filling numerical data\n",
    "\n",
    "df_train['LoanAmount'] = df_train['LoanAmount'].fillna(df_train['LoanAmount'].mean())\n",
    "df_train['Loan_Amount_Term'] = df_train['Loan_Amount_Term'].fillna(df_train['Loan_Amount_Term'].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:01.063160Z",
     "iopub.status.busy": "2024-11-18T17:19:01.062081Z",
     "iopub.status.idle": "2024-11-18T17:19:01.074750Z",
     "shell.execute_reply": "2024-11-18T17:19:01.073222Z",
     "shell.execute_reply.started": "2024-11-18T17:19:01.063105Z"
    }
   },
   "outputs": [],
   "source": [
    "# Crosschecking null values\n",
    "\n",
    "df_train.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:01.094500Z",
     "iopub.status.busy": "2024-11-18T17:19:01.094067Z",
     "iopub.status.idle": "2024-11-18T17:19:01.631768Z",
     "shell.execute_reply": "2024-11-18T17:19:01.630113Z",
     "shell.execute_reply.started": "2024-11-18T17:19:01.094459Z"
    }
   },
   "outputs": [],
   "source": [
    "#Visualising missing data to ensure all gaps have been covered\n",
    "sns.heatmap(df_train.isnull(), cbar=False, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:01.635772Z",
     "iopub.status.busy": "2024-11-18T17:19:01.634493Z",
     "iopub.status.idle": "2024-11-18T17:19:03.349799Z",
     "shell.execute_reply": "2024-11-18T17:19:03.348634Z",
     "shell.execute_reply.started": "2024-11-18T17:19:01.635700Z"
    }
   },
   "outputs": [],
   "source": [
    "#Using scatterplot to check for outliers\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "num_columns = ['LoanAmount', 'Loan_Amount_Term', 'ApplicantIncome', 'CoapplicantIncome']\n",
    "scatter_matrix(df_train[num_columns], figsize = (12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:03.351776Z",
     "iopub.status.busy": "2024-11-18T17:19:03.351337Z",
     "iopub.status.idle": "2024-11-18T17:19:13.246147Z",
     "shell.execute_reply": "2024-11-18T17:19:13.244786Z",
     "shell.execute_reply.started": "2024-11-18T17:19:03.351733Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:13.250257Z",
     "iopub.status.busy": "2024-11-18T17:19:13.249761Z",
     "iopub.status.idle": "2024-11-18T17:19:13.627786Z",
     "shell.execute_reply": "2024-11-18T17:19:13.626227Z",
     "shell.execute_reply.started": "2024-11-18T17:19:13.250204Z"
    }
   },
   "outputs": [],
   "source": [
    "#Further examination of numerical outliers\n",
    "plt.figure(figsize = (15,10))\n",
    "sns.boxplot(data=df_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:13.629983Z",
     "iopub.status.busy": "2024-11-18T17:19:13.629573Z",
     "iopub.status.idle": "2024-11-18T17:19:14.068162Z",
     "shell.execute_reply": "2024-11-18T17:19:14.066841Z",
     "shell.execute_reply.started": "2024-11-18T17:19:13.629941Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "\n",
    "Outlier_check = df_train[num_columns]\n",
    "sns.stripplot(data = Outlier_check, palette='dark:red', jitter = 0.3, size = 5)\n",
    "\n",
    "plt.title('Outlier Check')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers are being observed in the Applicantincome and Coapplicantincome columns. \n",
    "\n",
    "We will come back to this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T07:12:29.133615Z",
     "iopub.status.busy": "2024-10-14T07:12:29.133254Z",
     "iopub.status.idle": "2024-10-14T07:12:29.138076Z",
     "shell.execute_reply": "2024-10-14T07:12:29.136832Z",
     "shell.execute_reply.started": "2024-10-14T07:12:29.133576Z"
    }
   },
   "source": [
    "### Visualizing Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:14.070397Z",
     "iopub.status.busy": "2024-11-18T17:19:14.069896Z",
     "iopub.status.idle": "2024-11-18T17:19:16.470496Z",
     "shell.execute_reply": "2024-11-18T17:19:16.469207Z",
     "shell.execute_reply.started": "2024-11-18T17:19:14.070345Z"
    }
   },
   "outputs": [],
   "source": [
    "# Visualisng all categorical columns at once\n",
    "cat_columns = ['Gender', 'Married', 'Dependents', 'Education', 'Self_Employed', 'Credit_History', 'Property_Area', 'Loan_Status']\n",
    "\n",
    "\n",
    "#setting up plotting environment\n",
    "num_cat = len(cat_columns)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_cat, ncols=1, figsize = (10, 5*num_cat))\n",
    "\n",
    "#Plotting barchat of each categorical columns\n",
    "for i, col in enumerate(cat_columns):\n",
    "    sns.countplot(data=df_train, x=col, ax=axes[i], hue='Loan_Status', palette='Set2')\n",
    "    axes[i].set_title(f'plot of {col}')\n",
    "    axes[i].set_xticklabels(axes[i].get_xticklabels(), rotation = 45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:16.472599Z",
     "iopub.status.busy": "2024-11-18T17:19:16.472160Z",
     "iopub.status.idle": "2024-11-18T17:19:16.485525Z",
     "shell.execute_reply": "2024-11-18T17:19:16.484310Z",
     "shell.execute_reply.started": "2024-11-18T17:19:16.472549Z"
    }
   },
   "outputs": [],
   "source": [
    "dependents_0 = df_train[df_train['Dependents'] == '0']\n",
    "total_dependents_0 = len(dependents_0)\n",
    "loan_status_no = dependents_0[dependents_0['Loan_Status'] == 'No']\n",
    "percent_loan_status_no = (len(loan_status_no)/total_dependents_0)*100\n",
    "\n",
    "percent_loan_status_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:16.488205Z",
     "iopub.status.busy": "2024-11-18T17:19:16.487590Z",
     "iopub.status.idle": "2024-11-18T17:19:16.505228Z",
     "shell.execute_reply": "2024-11-18T17:19:16.503554Z",
     "shell.execute_reply.started": "2024-11-18T17:19:16.488113Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Filter rows where Dependents is '0'\n",
    "dependents_zero = df_train[df_train['Dependents'] == '0']\n",
    "\n",
    "# Step 2: Calculate the total number of Dependents '0'\n",
    "total_dependents_zero = len(dependents_zero)\n",
    "total_dependents_notzero = len(df_train[df_train['Dependents'] != '0'])\n",
    "\n",
    "# Step 3: Filter rows where Loan_Status is 'No' from the dependents_zero subset\n",
    "loan_status_no = dependents_zero[dependents_zero['Loan_Status'] == 'N']\n",
    "\n",
    "# Step 4: Calculate the percentage of Loan_Status 'No' in Dependents '0'\n",
    "percentage_no_loan = (len(loan_status_no) / total_dependents_zero) * 100\n",
    "\n",
    "print(f\"Total number of Dependents '0': {total_dependents_zero}\")\n",
    "print(f\"Total number of Dependents not '0': {total_dependents_notzero}\")\n",
    "print(f\"Percentage of Dependents '0' with Loan_Status 'No': {percentage_no_loan:.2f}%\")\n",
    "print (len(df_train['Dependents']))\n",
    "print (len(loan_status_no))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Outliers in the Numerical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T09:00:42.700613Z",
     "iopub.status.busy": "2024-10-14T09:00:42.699587Z",
     "iopub.status.idle": "2024-10-14T09:00:42.707674Z",
     "shell.execute_reply": "2024-10-14T09:00:42.706012Z",
     "shell.execute_reply.started": "2024-10-14T09:00:42.700562Z"
    }
   },
   "source": [
    "We use Interquartile Range(IQR) to peg down Outliers.\n",
    "\n",
    "Conventionally, values outside 1.5 * IQR are typically considered Outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:16.507366Z",
     "iopub.status.busy": "2024-11-18T17:19:16.506964Z",
     "iopub.status.idle": "2024-11-18T17:19:16.534006Z",
     "shell.execute_reply": "2024-11-18T17:19:16.532589Z",
     "shell.execute_reply.started": "2024-11-18T17:19:16.507309Z"
    }
   },
   "outputs": [],
   "source": [
    "#Calculating IQR for Applicantincome\n",
    "\n",
    "Q1_app = df_train['ApplicantIncome'].quantile(0.25)\n",
    "Q3_app = df_train['ApplicantIncome'].quantile(0.75)\n",
    "IQR = Q3_app - Q1_app\n",
    "\n",
    "lowerbound_app = Q1_app - 1.5*IQR\n",
    "upperbound_app = Q3_app + 1.5*IQR\n",
    "\n",
    "outliers_app = df_train[(df_train['ApplicantIncome'] < lowerbound_app) | (df_train['ApplicantIncome'] > upperbound_app)]\n",
    "\n",
    "#calcuating IQR for coapplicant income\n",
    "\n",
    "Q1_co = df_train['CoapplicantIncome'].quantile(0.25)\n",
    "Q3_co = df_train['CoapplicantIncome'].quantile(0.75)\n",
    "IQR_co = Q3_co - Q1_co\n",
    "\n",
    "lowerbound_co = Q1_co - 1.5*IQR_co\n",
    "upperbound_co = Q3_co + 1.5*IQR_co\n",
    "\n",
    "outliers_co = df_train[(df_train['CoapplicantIncome'] < lowerbound_co) | (df_train['CoapplicantIncome'] > upperbound_co)]\n",
    "\n",
    "# Dropping the Outliers\n",
    "df_train = df_train[~((df_train['ApplicantIncome'] < lowerbound_app) | (df_train['ApplicantIncome'] > upperbound_app))]\n",
    "df_train = df_train[~((df_train['CoapplicantIncome'] < lowerbound_co) | (df_train['CoapplicantIncome'] > upperbound_co))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:16.539437Z",
     "iopub.status.busy": "2024-11-18T17:19:16.538991Z",
     "iopub.status.idle": "2024-11-18T17:19:16.879826Z",
     "shell.execute_reply": "2024-11-18T17:19:16.878648Z",
     "shell.execute_reply.started": "2024-11-18T17:19:16.539395Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 9))\n",
    "\n",
    "outlier_check2 = df_train[num_columns]\n",
    "sns.stripplot(data=outlier_check2, palette='dark:red', jitter = 0.3, size = 5)\n",
    "plt.show()\n",
    "\n",
    "print ('Shape of treated dataset: ', df_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed from the plot above that the outliers in the numerical columns have been taken care of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observing Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:16.882330Z",
     "iopub.status.busy": "2024-11-18T17:19:16.881384Z",
     "iopub.status.idle": "2024-11-18T17:19:17.345955Z",
     "shell.execute_reply": "2024-11-18T17:19:17.344578Z",
     "shell.execute_reply.started": "2024-11-18T17:19:16.882285Z"
    }
   },
   "outputs": [],
   "source": [
    "#Selecting numeric columns from dataset\n",
    "numeric_df = df_train.select_dtypes(include=[np.number]) \n",
    "\n",
    "plt.figure(figsize=(12, 9))\n",
    "\n",
    "sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* It is observed that Applicant income is positively correlated with loan status \n",
    "* Co-applicant income appears to be slightly correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot Encoding Categorical variables\n",
    "\n",
    "Categorical values will be converted into numerical ones to ease model building.\n",
    "\n",
    "Pandas' get_dummies() library will be used for this.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.347994Z",
     "iopub.status.busy": "2024-11-18T17:19:17.347576Z",
     "iopub.status.idle": "2024-11-18T17:19:17.367003Z",
     "shell.execute_reply": "2024-11-18T17:19:17.365710Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.347952Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns = cat_columns, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling\n",
    "\n",
    "Standardizing numerical features to bring them to a common scale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.369077Z",
     "iopub.status.busy": "2024-11-18T17:19:17.368674Z",
     "iopub.status.idle": "2024-11-18T17:19:17.383291Z",
     "shell.execute_reply": "2024-11-18T17:19:17.382087Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.369036Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "standard_scaler= StandardScaler()\n",
    "\n",
    "df_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']] = standard_scaler.fit_transform(df_train[['ApplicantIncome', 'CoapplicantIncome', 'LoanAmount']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:12:57.767022Z",
     "iopub.status.busy": "2024-10-14T15:12:57.766016Z",
     "iopub.status.idle": "2024-10-14T15:12:57.778106Z",
     "shell.execute_reply": "2024-10-14T15:12:57.776800Z",
     "shell.execute_reply.started": "2024-10-14T15:12:57.766951Z"
    }
   },
   "source": [
    "## Creating new features\n",
    "\n",
    "Combining features to create new relationships.\n",
    "\n",
    "New relationships:\n",
    "\n",
    "* Total Income = Applicant Income + Co-applicant income\n",
    "* Loan-to-income ratio = Loan amount / Total income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.385472Z",
     "iopub.status.busy": "2024-11-18T17:19:17.385116Z",
     "iopub.status.idle": "2024-11-18T17:19:17.415137Z",
     "shell.execute_reply": "2024-11-18T17:19:17.413695Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.385433Z"
    }
   },
   "outputs": [],
   "source": [
    "#Total Income\n",
    "\n",
    "df_train['Total_Income'] = df_train['ApplicantIncome'] + df_train['CoapplicantIncome']\n",
    "\n",
    "#Loan-to-income Ratio\n",
    "\n",
    "df_train['Loan_to_Income'] = df_train['LoanAmount']/df_train['Total_Income'] \n",
    "\n",
    "# Viewing the updated features\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.417493Z",
     "iopub.status.busy": "2024-11-18T17:19:17.416957Z",
     "iopub.status.idle": "2024-11-18T17:19:17.432586Z",
     "shell.execute_reply": "2024-11-18T17:19:17.431179Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.417398Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train['Loan_Status_Y'].value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Loan status feature appear to be balanced.\n",
    "\n",
    "No requirement for further sampling to correct for overfitting or underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.434877Z",
     "iopub.status.busy": "2024-11-18T17:19:17.434349Z",
     "iopub.status.idle": "2024-11-18T17:19:17.464076Z",
     "shell.execute_reply": "2024-11-18T17:19:17.462909Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.434833Z"
    }
   },
   "outputs": [],
   "source": [
    "# dropping unneeded columns\n",
    "\n",
    "df_train = df_train.drop(['Loan_ID', 'Loan_Amount_Term'], axis=1)\n",
    "\n",
    "column_update = {'Gender_Male': 'Gender', 'Married_Yes': 'Married',\n",
    "                'Self_Employed_Yes': 'Self_Employed', 'Loan_Status_Y': 'Loan_Status' }\n",
    "\n",
    "df_train.rename(columns=column_update, inplace=True)\n",
    "\n",
    "#Display updated dataset\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-14T15:45:07.404046Z",
     "iopub.status.busy": "2024-10-14T15:45:07.403388Z",
     "iopub.status.idle": "2024-10-14T15:45:07.426254Z",
     "shell.execute_reply": "2024-10-14T15:45:07.424810Z",
     "shell.execute_reply.started": "2024-10-14T15:45:07.403986Z"
    }
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "1. Split the dataset into Features and Targets.\n",
    "\n",
    "2. Train-Test Split: Split data into training and test sets (80% train, 20% test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.466445Z",
     "iopub.status.busy": "2024-11-18T17:19:17.466030Z",
     "iopub.status.idle": "2024-11-18T17:19:17.478295Z",
     "shell.execute_reply": "2024-11-18T17:19:17.476902Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.466389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting into features vs targets\n",
    "\n",
    "X = df_train.drop(columns = ['Loan_Status']) #Features\n",
    "\n",
    "Y = df_train['Loan_Status'] #Target variables\n",
    "\n",
    "print ('Shape of X: ', X.shape)\n",
    "print ('Shape of Y: ', Y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.480416Z",
     "iopub.status.busy": "2024-11-18T17:19:17.480010Z",
     "iopub.status.idle": "2024-11-18T17:19:17.493959Z",
     "shell.execute_reply": "2024-11-18T17:19:17.491918Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.480374Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting into Training and Target variables\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.498120Z",
     "iopub.status.busy": "2024-11-18T17:19:17.496118Z",
     "iopub.status.idle": "2024-11-18T17:19:17.504841Z",
     "shell.execute_reply": "2024-11-18T17:19:17.503332Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.498055Z"
    }
   },
   "outputs": [],
   "source": [
    "#IMporting evealuation metrics\n",
    "from sklearn.metrics import accuracy_score, classification_report, log_loss\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-06T14:41:24.346028Z",
     "iopub.status.busy": "2024-11-06T14:41:24.344989Z",
     "iopub.status.idle": "2024-11-06T14:41:24.351902Z",
     "shell.execute_reply": "2024-11-06T14:41:24.350953Z",
     "shell.execute_reply.started": "2024-11-06T14:41:24.345979Z"
    }
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.507201Z",
     "iopub.status.busy": "2024-11-18T17:19:17.506781Z",
     "iopub.status.idle": "2024-11-18T17:19:17.517334Z",
     "shell.execute_reply": "2024-11-18T17:19:17.516062Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.507158Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.519326Z",
     "iopub.status.busy": "2024-11-18T17:19:17.518993Z",
     "iopub.status.idle": "2024-11-18T17:19:17.560251Z",
     "shell.execute_reply": "2024-11-18T17:19:17.558928Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.519289Z"
    }
   },
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(X_train, Y_train)\n",
    "\n",
    "log_reg_predict = log_reg.predict(X_train)\n",
    "\n",
    "#Accuracy_score\n",
    "\n",
    "log_reg_accuracy = accuracy_score(Y_train, log_reg_predict)\n",
    "print ('Logistic Regression Accuracy: ', log_reg_accuracy)\n",
    "\n",
    "log_reg_prob = log_reg.predict_proba(X_train)\n",
    "log_reg_log_loss = log_loss(Y_train, log_reg_prob)\n",
    "print(\"Logistic Regression Log Loss:\", log_reg_log_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.562045Z",
     "iopub.status.busy": "2024-11-18T17:19:17.561702Z",
     "iopub.status.idle": "2024-11-18T17:19:17.572964Z",
     "shell.execute_reply": "2024-11-18T17:19:17.571578Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.562008Z"
    }
   },
   "outputs": [],
   "source": [
    "log_predict_test = log_reg.predict(X_test)\n",
    "\n",
    "#Accuracy Score\n",
    "\n",
    "log_test_accuracy = accuracy_score(Y_test, log_predict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.575121Z",
     "iopub.status.busy": "2024-11-18T17:19:17.574657Z",
     "iopub.status.idle": "2024-11-18T17:19:17.599957Z",
     "shell.execute_reply": "2024-11-18T17:19:17.598569Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.575079Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Initialize and Train\n",
    "\n",
    "tree_clf = DecisionTreeClassifier()\n",
    "\n",
    "tree_clf.fit(X_train, Y_train)\n",
    "tree_clf_predict = tree_clf.predict(X_train)\n",
    "\n",
    "#Accuracy Score\n",
    "\n",
    "tree_clf_accuracy = accuracy_score(Y_train, tree_clf_predict)\n",
    "print ('Logistic Regression Accuracy: ', tree_clf_accuracy)\n",
    "\n",
    "tree_clf_prob = tree_clf.predict_proba(X_train)\n",
    "tree_clf_log_loss = log_loss(Y_train, tree_clf_prob)\n",
    "print ('Logistic Regression Log Loss: ', tree_clf_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree appears to be Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.601676Z",
     "iopub.status.busy": "2024-11-18T17:19:17.601291Z",
     "iopub.status.idle": "2024-11-18T17:19:17.930230Z",
     "shell.execute_reply": "2024-11-18T17:19:17.928910Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.601636Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = RandomForestClassifier()\n",
    "\n",
    "forest_clf.fit(X_train, Y_train)\n",
    "forest_clf_predict = forest_clf.predict(X_train)\n",
    "\n",
    "#Accuracy\n",
    "\n",
    "forest_clf_accuracy = accuracy_score(Y_train, forest_clf_predict)\n",
    "print ('Random Forest Classifier accuracy: ', forest_clf_accuracy)\n",
    "\n",
    "forest_clf_prob = forest_clf.predict_proba(X_train)\n",
    "forest_clf_log_loss = log_loss(Y_train, forest_clf_prob)\n",
    "print ('Random Forest Classifier Log Loss: ', forest_clf_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:17.932355Z",
     "iopub.status.busy": "2024-11-18T17:19:17.931930Z",
     "iopub.status.idle": "2024-11-18T17:19:18.018595Z",
     "shell.execute_reply": "2024-11-18T17:19:18.017149Z",
     "shell.execute_reply.started": "2024-11-18T17:19:17.932311Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(probability = True)\n",
    "\n",
    "svm_clf.fit(X_train, Y_train)\n",
    "svm_clf_predict = svm_clf.predict(X_train)\n",
    "\n",
    "#Accuracy\n",
    "\n",
    "svm_clf_accuracy = accuracy_score(Y_train, svm_clf_predict)\n",
    "print ('Support Vector Machine Accuracy: ', svm_clf_accuracy)\n",
    "\n",
    "#Logloss\n",
    "\n",
    "svm_clf_prob = svm_clf.predict_proba(X_train)\n",
    "svm_clf_log_loss = log_loss(Y_train, svm_clf_prob)\n",
    "print ('Support Vector Machine Log Loss: ', svm_clf_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Accuracy of Different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:18.020713Z",
     "iopub.status.busy": "2024-11-18T17:19:18.020282Z",
     "iopub.status.idle": "2024-11-18T17:19:18.125871Z",
     "shell.execute_reply": "2024-11-18T17:19:18.124739Z",
     "shell.execute_reply.started": "2024-11-18T17:19:18.020671Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "#Dictionary to store evaluation metrics\n",
    "metrics = {}\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': log_reg,\n",
    "    'Decision Tree': tree_clf,\n",
    "    'Forest Classifier': forest_clf,\n",
    "    'Support Vector Machine': svm_clf\n",
    "}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    #Predict CLass labels\n",
    "    test_prediction = model.predict(X_test)\n",
    "\n",
    "    # If `predict_proba` is available, get probabilities for log loss\n",
    "    try:\n",
    "        test_probabilities = model.predict_proba(X_test)\n",
    "        model_log_loss = log_loss(Y_test, test_probabilities)\n",
    "    except AttributeError:\n",
    "        model_log_loss = 'N/A'\n",
    "\n",
    "    #Calculating metrics\n",
    "\n",
    "    model_accuracy = accuracy_score(Y_test, test_prediction)\n",
    "    model_precision = precision_score(Y_test, test_prediction, average='binary')\n",
    "    model_recall = recall_score(Y_test, test_prediction, average='binary')\n",
    "    model_f1 = f1_score(Y_test, test_prediction, average='binary')\n",
    "\n",
    "    # Store metrics\n",
    "    metrics[model_name] = {\n",
    "        'Accuracy': model_accuracy,\n",
    "        'Precision': model_precision,\n",
    "        'Recall': model_recall,\n",
    "        'F1_Score': model_f1,\n",
    "        'Log_Loss': model_log_loss\n",
    "    }\n",
    "\n",
    "#Display results\n",
    "\n",
    "for metric_name, metric_value in metrics.items():\n",
    "    print (f'{metric_name}: {metric_value}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "Logistic Regression and SVM are the strongest performers with high accuracy, precision, and recall, and both provide reliable probability estimates.\n",
    "Random Forest is also solid, but slightly trails Logistic Regression and SVM.\n",
    "Decision Tree has noticeably lower performance across all metrics, suggesting it may not generalize as well to this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:18.127586Z",
     "iopub.status.busy": "2024-11-18T17:19:18.127218Z",
     "iopub.status.idle": "2024-11-18T17:19:18.325540Z",
     "shell.execute_reply": "2024-11-18T17:19:18.324342Z",
     "shell.execute_reply.started": "2024-11-18T17:19:18.127541Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "#fit and predict\n",
    "xgb_clf.fit(X_train, Y_train)\n",
    "xgb_predict = xgb_clf.predict(X_test)\n",
    "\n",
    "#Calculatiing metrics\n",
    "xgb_accuracy = accuracy_score(Y_test, xgb_predict)\n",
    "xgb_precision = precision_score(Y_test, xgb_predict)\n",
    "xgb_recall = recall_score(Y_test, xgb_predict)\n",
    "xgb_f1 = f1_score(Y_test, xgb_predict)\n",
    "\n",
    "#log_loss\n",
    "xgb_probability = xgb_clf.predict_proba(X_test)\n",
    "xgb_log_loss = log_loss(Y_test, xgb_probability)\n",
    "\n",
    "print(\"XGBoost Results\")\n",
    "print(\"Accuracy:\", xgb_accuracy)\n",
    "print(\"Precision:\", xgb_precision)\n",
    "print(\"Recall:\", xgb_recall)\n",
    "print(\"F1 Score:\", xgb_f1)\n",
    "print(\"Log Loss:\", xgb_log_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability\n",
    "\n",
    "Viewing the level of contribution each feature makes to the predictive power of the **Logistic Regression model**(our model of choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:18.332744Z",
     "iopub.status.busy": "2024-11-18T17:19:18.331793Z",
     "iopub.status.idle": "2024-11-18T17:19:18.774256Z",
     "shell.execute_reply": "2024-11-18T17:19:18.772858Z",
     "shell.execute_reply.started": "2024-11-18T17:19:18.332692Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Logistic Regression example\n",
    "result = permutation_importance(log_reg, X_test, Y_test, n_repeats=10, random_state=42)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X_test.columns,\n",
    "    'Importance': result.importances_mean\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(feature_importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:18.776139Z",
     "iopub.status.busy": "2024-11-18T17:19:18.775662Z",
     "iopub.status.idle": "2024-11-18T17:19:19.112003Z",
     "shell.execute_reply": "2024-11-18T17:19:19.110780Z",
     "shell.execute_reply.started": "2024-11-18T17:19:18.776083Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='skyblue')\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Feature Importance of Each Feature')\n",
    "plt.title('Feature Importance of Each Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T16:47:59.167461Z",
     "iopub.status.busy": "2024-11-18T16:47:59.166926Z",
     "iopub.status.idle": "2024-11-18T16:47:59.176680Z",
     "shell.execute_reply": "2024-11-18T16:47:59.175049Z",
     "shell.execute_reply.started": "2024-11-18T16:47:59.167412Z"
    }
   },
   "source": [
    "This reveals that Credit History is by far the most influential decider on the eligibility of receiving loans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-18T17:19:19.114231Z",
     "iopub.status.busy": "2024-11-18T17:19:19.113759Z",
     "iopub.status.idle": "2024-11-18T17:19:19.121636Z",
     "shell.execute_reply": "2024-11-18T17:19:19.120345Z",
     "shell.execute_reply.started": "2024-11-18T17:19:19.114178Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open ('Elgibility Prediction Model.pkl', 'wb') as file:\n",
    "    pickle.dump(log_reg, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3378270,
     "sourceId": 5877232,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
